<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Verification</title>
    <link rel="stylesheet" href="css/app.css">
    <!-- Inline styles to override CSS that hides camera -->
    <style>
        .face-section__camera-container {
            display: block !important; /* Override display:none */
            position: relative !important;
            width: 640px !important;
            height: 480px !important;
            margin: 0 auto !important;
            background-color: #000 !important;
            border-radius: 8px !important;
            overflow: hidden !important;
        }
        
        .face-section__video {
            position: absolute !important;
            width: 100% !important;
            height: 100% !important;
            object-fit: cover !important;
        }
        
        .output-section__canvas {
            position: absolute !important;
            width: 100% !important;
            height: 100% !important;
            z-index: 2 !important;
        }
    </style>
</head>
<body>
    <!-- Toast notifications container -->
    <div id="toast-container" class="toast-container" aria-live="polite" role="region"></div>

    <!-- Application Header -->
    <header class="app-header">
        <h1 class="app-header__title">Face Verification</h1>
        <a href="app.html" class="app-header__back">Back</a>
    </header>

    <!-- Main Application Content -->
    <main class="app-main">
        <ol class="stepper">
            <li class="stepper__item is-current">Upload JSON</li>
            <li class="stepper__item">Start Camera</li>
            <li class="stepper__item">Verify Face</li>
        </ol>

        <!-- Status Indicator Component -->
        <section class="status-indicator" aria-live="polite">
            <p class="status-indicator__text">Please upload your face ID JSON file</p>
            <progress class="status-indicator__progress" value="0" max="100"></progress>
        </section>

        <!-- Upload Module for Descriptor JSON -->
        <section id="upload-module" class="upload-module">
            <label for="jsonFileInput" class="upload-module__label">Upload Face ID JSON:</label>
            <input type="file" id="jsonFileInput" class="upload-module__input" accept=".json">
            <button id="submit-json" class="button button--primary">Submit JSON</button>
        </section>

        <!-- Face Detection and Controls (initially hidden) -->
        <section id="face-detection-section" class="face-section" aria-live="off" style="display: none;">
            <div class="face-section__camera-container">
                <video id="video" class="face-section__video" autoplay muted playsinline></video>
                <canvas id="output-canvas" class="output-section__canvas" role="img" aria-label="Processed video with face overlays"></canvas>
            </div>
        </section>

        <!-- User Instructions -->
        <section class="instructions">
            <p>
                First, upload the face ID JSON file that was generated during registration.
                After submitting, the camera will start automatically and validate your face against the stored data.
            </p>
        </section>
    </main>

    <!-- Load scripts -->
    <script src="js/face-api.js"></script>
    <script type="module">
        // Import necessary modules
        import { updateStatus, showToast } from './js/modules/ui.js';
        import { startCamera, getVideoElement } from './js/modules/camera.js';
        import { initDetection } from './js/modules/detection.js';
        import { initWorker } from './js/modules/workerController.js';
        import { drawImageDataToCanvas } from './js/modules/renderer.js';
        import { handleVerify, setAction, setDescriptors } from './js/modules/faceService.js';
        import { updateStepper } from './js/modules/setupUI.js';

        // Global worker reference
        let worker = null;

        document.addEventListener('DOMContentLoaded', async () => {
            try {
                // First, ensure service worker is registered
                await registerServiceWorker();
                
                // Set action to verify
                setAction('verify');
                
                // Initialize service worker and models
                updateStatus('Initializing face detection models...', 30);
                worker = await initWorker((payload) => {
                    const detections = payload.detections;
                    if (detections && detections[0] && detections[0][0] && detections[0][0].descriptor) {
                        const descriptor = new Float32Array(detections[0][0].descriptor);
                        handleVerify(descriptor);
                    }
                    drawImageDataToCanvas(detections, 'output-canvas');
                });
                
                if (!worker) {
                    throw new Error('Failed to initialize face detection worker');
                }
                
                updateStatus('Ready to upload face ID', 100);
                
                // Set up JSON upload and submit button event handlers
                setupJsonSubmitHandler();
            } catch (error) {
                console.error('Error initializing verification:', error);
                updateStatus('Error: ' + error.message, 0);
                showToast('Failed to initialize face verification. Please try again.', 'error');
            }
        });

        /**
         * Ensures the service worker is registered
         * @returns {Promise<void>}
         */
        async function registerServiceWorker() {
            updateStatus('Checking service worker...', 10);
            
            if ('serviceWorker' in navigator) {
                try {
                    // Check if service worker is already active
                    const existingReg = await navigator.serviceWorker.getRegistration();
                    
                    if (existingReg) {
                        console.log('Service Worker already registered');
                        return;
                    }
                    
                    // Register service worker if not already registered
                    const registration = await navigator.serviceWorker.register('./faceDetectionServiceWorker.js', {
                        scope: './'
                    });
                    console.log('Service Worker registered with scope:', registration.scope);
                } catch (error) {
                    console.error('Service Worker registration failed:', error);
                    throw new Error('Failed to register service worker: ' + error.message);
                }
            } else {
                throw new Error('Service Workers not supported in this browser');
            }
        }
        
        /**
         * Sets up the JSON file upload and submit handler
         */
        function setupJsonSubmitHandler() {
            const submitButton = document.getElementById('submit-json');
            const fileInput = document.getElementById('jsonFileInput');
            
            submitButton.addEventListener('click', async () => {
                // Validate file input
                const file = fileInput.files[0];
                if (!file) {
                    showToast('Please select a JSON file first', 'error');
                    return;
                }
                
                // Process the JSON file
                await processJsonFile(file);
            });
        }
        
        /**
         * Process the uploaded JSON file and start verification
         * @param {File} file - The uploaded JSON file
         */
        async function processJsonFile(file) {
            try {
                updateStatus('Loading face ID data...', 50);
                
                // Read and parse the file
                const text = await file.text();
                let parsed;
                
                try {
                    parsed = JSON.parse(text);
                } catch (parseError) {
                    showToast('Invalid JSON format. The file might be corrupted.', 'error');
                    updateStatus('Error: Invalid JSON format', 0);
                    return;
                }
                
                // Convert the data to descriptors
                const descriptors = convertToDescriptors(parsed);
                
                if (descriptors.length === 0) {
                    showToast('No valid face descriptors found in the JSON file. Please upload a valid face ID file.', 'error');
                    updateStatus('Error: Invalid face ID data', 0);
                    return;
                }

                // Set descriptors for verification
                setDescriptors(descriptors);
                showToast('Face ID loaded successfully', 'success');
                
                // Update UI
                updateStepper(2);
                updateStatus('Starting camera for verification...', 70);
                
                // Show face detection section
                document.getElementById('face-detection-section').style.display = 'block';
                
                // Start camera and face detection
                await startVerification();
            } catch (error) {
                console.error('Error processing JSON:', error);
                showToast('Failed to process JSON: ' + error.message, 'error');
                updateStatus('Error loading face ID file', 0);
            }
        }
        
        /**
         * Convert parsed JSON data to Float32Array descriptors
         * @param {Object|Array} data - The parsed JSON data
         * @returns {Float32Array[]} Array of descriptors
         */
        function convertToDescriptors(data) {
            // Handle different JSON structures
            let items = [];
            
            if (Array.isArray(data)) {
                items = data;
            } else if (data && typeof data === 'object') {
                items = Object.values(data);
            } else {
                return [];
            }
            
            return items
                .map(item => {
                    // Handle array format
                    if (Array.isArray(item) && item.length > 0) {
                        return new Float32Array(item);
                    }
                    // Handle object format
                    if (item && typeof item === 'object') {
                        const values = Object.values(item);
                        if (values.length > 0) {
                            return new Float32Array(values);
                        }
                    }
                    return null;
                })
                .filter(d => d !== null);
        }
        
        /**
         * Sets up continuous camera preview on the canvas
         * This ensures that the camera feed is visible even before face detection results arrive
         */
        function setupCameraPreview() {
            console.log('🎥 Setting up camera preview in module script');
            const video = document.getElementById('video');
            const canvas = document.getElementById('output-canvas');
            
            if (!canvas || !video) {
                console.error('❌ Video or canvas element not found in module script');
                return;
            }
            
            console.log('🖼️ Getting canvas context');
            const ctx = canvas.getContext('2d');
            
            // Track face detection status
            window.faceDetectionStatus = {
                faceDetected: false,
                lastUpdated: Date.now(),
                message: 'Waiting for face verification...'
            };
            
            // Draw video frame to canvas continuously
            function drawVideoFrame() {
                if (video.readyState === video.HAVE_ENOUGH_DATA) {
                    // Set canvas size to match video
                    if (canvas.width !== video.videoWidth || canvas.height !== video.videoHeight) {
                        canvas.width = video.videoWidth;
                        canvas.height = video.videoHeight;
                        console.log(`🖼️ Canvas dimensions set to: ${canvas.width}x${canvas.height}`);
                    }
                    
                    // Draw the video frame
                    ctx.drawImage(video, 0, 0);
                    
                    // Add a message while waiting for face verification
                    // Use the status from the global variable that can be updated by detection.js
                    ctx.font = '24px Arial';
                    ctx.fillStyle = 'white';
                    ctx.strokeStyle = 'black';
                    ctx.lineWidth = 2;
                    
                    const message = window.faceDetectionStatus ? window.faceDetectionStatus.message : 'Waiting for face verification...';
                    const textWidth = ctx.measureText(message).width;
                    const x = (canvas.width - textWidth) / 2;
                    const y = 40;
                    
                    ctx.strokeText(message, x, y);
                    ctx.fillText(message, x, y);
                    
                    // If more than 5 seconds have passed since last status update, reset to waiting
                    const now = Date.now();
                    if (now - window.faceDetectionStatus.lastUpdated > 5000) {
                        window.faceDetectionStatus.message = 'Waiting for face verification...';
                        window.faceDetectionStatus.faceDetected = false;
                    }
                }
                
                // Continue drawing only if video is playing and not paused
                if (!video.paused && !video.ended) {
                    requestAnimationFrame(drawVideoFrame);
                }
            }
            
            // Start drawing when video starts playing
            video.addEventListener('play', () => {
                console.log('▶️ Video play event captured in module script, starting animation frame');
                drawVideoFrame();
            });
            
            // Start animation if video is already playing
            if (video.readyState >= 2 && !video.paused && !video.ended) {
                console.log('▶️ Video is already playing, starting animation frame directly');
                drawVideoFrame();
            }
        }
        
        /**
         * Start the camera and face verification process
         */
        async function startVerification() {
            try {
                console.log('🎬 Starting verification process');
                
                // Start camera
                console.log('🎥 Starting camera');
                await startCamera();
                
                // Set up canvas preview 
                console.log('🖼️ Setting up camera preview');
                setupCameraPreview();
                
                // Hook into detection.js message handling
                const originalUpdateStatus = window.updateStatus || function() {};
                window.updateStatus = function(message, progress) {
                    console.log(`🔄 Status update: ${message} (${progress}%)`);
                    
                    // Update global face detection status for the canvas to use
                    if (message.includes('Face detected')) {
                        window.faceDetectionStatus = {
                            faceDetected: true,
                            lastUpdated: Date.now(),
                            message: 'Face detected! Processing verification...'
                        };
                        console.log('✅ Face detected, updated status');
                    } else if (message.includes('No face detected')) {
                        window.faceDetectionStatus = {
                            faceDetected: false,
                            lastUpdated: Date.now(),
                            message: 'No face detected. Please look at the camera.'
                        };
                        console.log('❌ No face detected, updated status');
                    }
                    
                    // Call the original function
                    originalUpdateStatus(message, progress);
                };
                
                // Start detection
                if (worker) {
                    console.log('🔍 Initializing face detection');
                    initDetection(worker);
                    updateStatus('Ready for face verification', 100);
                    updateStepper(3);
                } else {
                    throw new Error('Face detection worker not initialized');
                }
            } catch (error) {
                console.error('❌ Error starting verification:', error);
                showToast('Failed to start camera: ' + error.message, 'error');
                updateStatus('Error starting verification', 0);
            }
        }
    </script>
    <script>
    // Add a function to manually test if face detection is working
    function testFaceDetection() {
        console.log('🧪 Manual face detection test initiated');
        try {
            // Log current face detection status
            console.log('Current face detection status:', window.faceDetectionStatus);
            
            // Add one-time listener for test response
            const testResponseHandler = function(event) {
                if (event.data && event.data.type === 'TEST_RESULT') {
                    console.log('📊 Received test results from service worker:', event.data.status);
                    
                    // If models aren't loaded, show an error
                    if (!event.data.status.isModelLoaded) {
                        console.error('❌ Face detection models are not loaded!');
                        window.faceDetectionStatus = {
                            faceDetected: false,
                            lastUpdated: Date.now(),
                            message: 'Error: Face detection models not loaded!'
                        };
                    } else {
                        console.log('✅ Face detection models are loaded correctly');
                    }
                    
                    // Remove the listener after receiving the response
                    navigator.serviceWorker.removeEventListener('message', testResponseHandler);
                }
            };
            
            // Add the listener
            navigator.serviceWorker.addEventListener('message', testResponseHandler);
            
            // Check if service worker is active
            navigator.serviceWorker.getRegistration().then(reg => {
                if (reg && reg.active) {
                    console.log('✅ Service worker is active:', reg.active.scriptURL);
                    
                    // Send a ping to the service worker
                    reg.active.postMessage({ 
                        type: 'TEST_FACE_DETECTION',
                        timestamp: Date.now()
                    });
                    
                    console.log('📤 Test message sent to service worker');
                } else {
                    console.log('❌ No active service worker found');
                }
            });
            
            return '🧪 Test initiated, check console for results';
        } catch (error) {
            console.error('❌ Test failed:', error);
            return '❌ Test failed: ' + error.message;
        }
    }
    
    document.addEventListener('DOMContentLoaded', async () => {
        try {
            console.log('🚀 Secondary script initializing');
            // Get DOM elements
            const statusElement = document.querySelector('.status-indicator__text');
            const videoEl = document.getElementById('video');
            const canvasEl = document.getElementById('output-canvas');

            if (!videoEl || !canvasEl) {
                console.error('❌ Video or Canvas element not found in secondary script');
                return;
            }

            // Only run this if we're not using the module system
            if (typeof window.workerInitialized === 'undefined') {
                console.log('🔄 Secondary script running as module not initialized');
                // Update status and start camera first
                statusElement.textContent = 'Starting camera...';
                await setupCamera();
                statusElement.textContent = 'Camera started. Setting up canvas preview...';

                // Setup canvas
                const ctx = canvasEl.getContext('2d');
                
                // Function to draw video frame on canvas
                function drawVideoFrame() {
                    if (!videoEl || !canvasEl || !ctx) {
                        console.error('❌ Video, Canvas, or Context not available');
                        return;
                    }
                    
                    // Make sure canvas dimensions match video
                    if (canvasEl.width !== videoEl.videoWidth || canvasEl.height !== videoEl.videoHeight) {
                        canvasEl.width = videoEl.videoWidth;
                        canvasEl.height = videoEl.videoHeight;
                        console.log(`🖼️ Canvas dimensions set to: ${canvasEl.width}x${canvasEl.height} in secondary script`);
                    }
                    
                    // Draw the video frame
                    if (videoEl.readyState === videoEl.HAVE_ENOUGH_DATA) {
                        ctx.drawImage(videoEl, 0, 0, canvasEl.width, canvasEl.height);
                        
                        // Get status from the global variable that can be updated by the module script
                        const status = window.faceDetectionStatus || { 
                            message: 'Waiting for face detection module to initialize...' 
                        };
                        
                        // Add text indicating waiting for face
                        ctx.font = '20px Arial';
                        ctx.fillStyle = 'white';
                        ctx.fillText(status.message, 20, 30);
                        
                        // Log status periodically (every 3 seconds) to not flood the console
                        const now = Date.now();
                        if (!window.lastStatusLog || now - window.lastStatusLog > 3000) {
                            console.log(`🔄 Current face detection status: ${status.message}`);
                            window.lastStatusLog = now;
                        }
                    }
                    
                    // Continue drawing frames
                    requestAnimationFrame(drawVideoFrame);
                }
                
                // Mark that we've initialized
                window.workerInitialized = true;
                console.log('✅ Marked worker as initialized in secondary script');
                
                // Start drawing video frames
                console.log('🎬 Starting canvas animation in secondary script');
                drawVideoFrame();
            } else {
                console.log('ℹ️ Secondary script skipped as module system is active');
            }
            
            async function setupCamera() {
                try {
                    const constraints = {
                        video: {
                            width: 640,
                            height: 480,
                            facingMode: 'user'
                        }
                    };
                    
                    const stream = await navigator.mediaDevices.getUserMedia(constraints);
                    videoEl.srcObject = stream;
                    
                    return new Promise((resolve) => {
                        videoEl.onloadedmetadata = () => {
                            videoEl.play();
                            resolve();
                        };
                    });
                } catch (error) {
                    console.error('Error setting up camera:', error);
                    statusElement.textContent = `Error setting up camera: ${error.message}`;
                    throw error;
                }
            }

            // Update verification status
            function updateVerificationStatus(isVerified) {
                if (isVerified) {
                    statusElement.textContent = 'Face verified successfully!';
                    statusElement.style.color = 'green';
                } else {
                    statusElement.textContent = 'Face verification failed!';
                    statusElement.style.color = 'red';
                }
            }

            // Note: The faceVerificationElement click handler is commented out as it's handled by the module system
            // Uncomment and adapt if needed for direct verification without modules
            /*
            faceVerificationElement.addEventListener('click', async () => {
                try {
                    statusElement.textContent = 'Verifying face...';
                    
                    // Capture current frame from canvas
                    const imageData = canvasEl.toDataURL('image/png');
                    
                    // Send the image to the server for verification
                    const response = await fetch('/verify-face', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify({ image: imageData })
                    });
                    
                    const result = await response.json();
                    
                    // Update verification status based on server response
                    updateVerificationStatus(result.verified);
                    
                } catch (error) {
                    console.error('Error during face verification:', error);
                    statusElement.textContent = `Error: ${error.message}`;
                }
            });
            */
        } catch (error) {
            console.error('Error in main process:', error);
            document.querySelector('.status-indicator__text').textContent = `Error: ${error.message}`;
        }
    });
    </script>
</body>
</html> 