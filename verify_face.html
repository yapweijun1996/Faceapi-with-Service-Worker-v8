<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Verification</title>
    <link rel="stylesheet" href="css/app.css">
    <!-- Inline styles to override CSS that hides camera -->
    <style>
        .face-section__camera-container {
            display: block !important; /* Override display:none */
            position: relative !important;
            width: 640px !important;
            height: 480px !important;
            margin: 0 auto !important;
            background-color: #000 !important;
            border-radius: 8px !important;
            overflow: hidden !important;
        }
        
        .face-section__video {
            position: absolute !important;
            width: 100% !important;
            height: 100% !important;
            object-fit: cover !important;
        }
        
        .output-section__canvas {
            position: absolute !important;
            width: 100% !important;
            height: 100% !important;
            z-index: 2 !important;
        }
        
        /* Styles for model status indicator */
        .model-status {
            margin-top: 10px;
            padding: 5px 10px;
            font-size: 14px;
            border-radius: 4px;
            background-color: #f5f5f5;
            text-align: center;
        }
        
        /* Loading spinner for models */
        .loading-spinner {
            display: inline-block;
            width: 16px;
            height: 16px;
            border: 2px solid rgba(0, 0, 0, 0.1);
            border-top-color: #3498db;
            border-radius: 50%;
            animation: spin 1s infinite linear;
            margin-right: 8px;
            vertical-align: middle;
        }
        
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
    </style>
</head>
<body>
    <!-- Toast notifications container -->
    <div id="toast-container" class="toast-container" aria-live="polite" role="region"></div>

    <!-- Application Header -->
    <header class="app-header">
        <h1 class="app-header__title">Face Verification</h1>
        <a href="app.html" class="app-header__back">Back</a>
    </header>

    <!-- Main Application Content -->
    <main class="app-main">
        <ol class="stepper">
            <li class="stepper__item is-current">Upload JSON</li>
            <li class="stepper__item">Start Camera</li>
            <li class="stepper__item">Verify Face</li>
        </ol>

        <!-- Status Indicator Component -->
        <section class="status-indicator" aria-live="polite">
            <p class="status-indicator__text">Please upload your face ID JSON file</p>
            <progress class="status-indicator__progress" value="0" max="100"></progress>
        </section>

        <!-- Upload Module for Descriptor JSON -->
        <section id="upload-module" class="upload-module">
            <label for="jsonFileInput" class="upload-module__label">Upload Face ID JSON:</label>
            <input type="file" id="jsonFileInput" class="upload-module__input" accept=".json" disabled>
            <button id="submit-json" class="button button--primary" disabled>Submit JSON</button>
            <p id="model-status" class="model-status">Loading face detection models... Please wait.</p>
        </section>

        <!-- Face Detection and Controls (initially hidden) -->
        <section id="face-detection-section" class="face-section" aria-live="off" style="display: none;">
            <div class="face-section__camera-container">
                <video id="video" class="face-section__video" autoplay muted playsinline></video>
                <canvas id="output-canvas" class="output-section__canvas" role="img" aria-label="Processed video with face overlays"></canvas>
            </div>
        </section>

        <!-- User Instructions -->
        <section class="instructions">
            <p>
                First, upload the face ID JSON file that was generated during registration.
                After submitting, the camera will start automatically and validate your face against the stored data.
            </p>
        </section>
    </main>

    <!-- Load scripts and main logic -->
    <script src="js/face-api.js"></script>
    <script type="module">
    import { updateStatus, showToast } from './js/modules/ui.js';
    import { startCamera } from './js/modules/camera.js';
    import { initDetection } from './js/modules/detection.js';
    import { initWorker } from './js/modules/workerController.js';
    import { drawImageDataToCanvas } from './js/modules/renderer.js';
    import { handleVerify, setAction, setDescriptors } from './js/modules/faceService.js';
    import { updateStepper } from './js/modules/setupUI.js';

    document.addEventListener('DOMContentLoaded', async () => {
      // Grab UI elements
      const fileInput = document.getElementById('jsonFileInput');
      const submitBtn = document.getElementById('submit-json');
      const detectionSection = document.getElementById('face-detection-section');
      const videoEl = document.getElementById('video');
      const canvasEl = document.getElementById('output-canvas');

      if (!fileInput || !submitBtn || !detectionSection || !videoEl || !canvasEl) {
        console.error('Required elements missing');
        return;
      }
      // Disable upload until models are ready
      fileInput.disabled = true;
      submitBtn.disabled = true;

      try {
        // Register and activate service worker
        updateStatus('Registering service worker...', 10);
        if (!('serviceWorker' in navigator)) throw new Error('Service Workers not supported');
        await navigator.serviceWorker.register('./js/faceDetectionServiceWorker.js', { scope: './' });
        await navigator.serviceWorker.ready;

        // Load face detection models
        updateStatus('Loading face detection models...', 30);
        setAction('verify');
        const worker = await initWorker(({ detections }) => {
          drawImageDataToCanvas(detections, 'output-canvas');
          if (detections?.[0]?.[0]?.descriptor) {
            handleVerify(new Float32Array(detections[0][0].descriptor));
          }
        });
        if (!worker) throw new Error('Failed to initialize face detection worker');

        updateStatus('Models loaded. Ready to upload JSON.', 100);
        showToast('Models loaded successfully.', 'success');

        // Enable JSON upload
        fileInput.disabled = false;
        submitBtn.disabled = false;

        // Handle JSON upload
        submitBtn.addEventListener('click', async () => {
          if (!fileInput.files.length) {
            showToast('Please select a JSON file', 'error');
            return;
          }
          updateStatus('Reading JSON...', 30);
          let json;
          try {
            json = JSON.parse(await fileInput.files[0].text());
          } catch {
            showToast('Invalid JSON file', 'error');
            updateStatus('Error: Invalid JSON', 0);
            return;
          }

          // Set descriptors and update UI
          setDescriptors(Object.values(json).map(arr => new Float32Array(arr)));
          updateStepper(2);

          // Show detection area and start camera
          updateStatus('Starting camera...', 50);
          detectionSection.style.display = 'block';
          await startCamera();

          // Start detection
          updateStatus('Running face detection...', 70);
          initDetection(worker);
          updateStatus('Verification in progress...', 100);
        });
      } catch (error) {
        console.error('Initialization error:', error);
        updateStatus('Error: ' + error.message, 0);
        showToast(error.message, 'error');
      }
    });
    </script>
</body>
</html> 